---
title: 메모리 관리와 IO 1) 컴퓨터 구조 (4)
categories: WindowsSystem
tags: 
toc: true
toc_sticky: true
---

이 포스트는 윤성우님의 <뇌를 자극하는 윈도우즈 시스템 프로그래밍 (한빛미디어)> 내용을 바탕으로 공부한 내용을 정리한 것입니다. 

# **1. 메모리**

## **1) 메모리의 종류**

**메인 메모리**

메인 메모리가 반드시 램이어야 할 이유는 없으나 대부분의 컴퓨터에서 메인 메모리로 램, 정확히는 D-RAM 계열의 메모리를 사용하기 때문에 이 두 용어를 같이 사용하는 경우가 많다. 

**레지스터**

CPU에 내장되어 연산을 위한 저장소를 제공한다. 저장소라는 의미에서 이 역시 메모리의 일부이다. 

**캐쉬**

일반적으로 D-RAM 보다 빠른 S-RAM으로 구성되는데, 이는 CPU와 램 사이에서 중간 저장소 역할을 하는 메모리이다. CPU에 근접한 메모리이지 CPU의 일부로 존재하는 메모리는 아니다. 

**하드디스크 및 그 외 저장 장치**

하드디스크 역시 크고 작은 파일들을 저장하기 위한 용도로 사용되며, 프로그램 실행에서도 중요한 의미를 지닌다. 그 외에 SD 카드, CD ROM 같은 IO 장치 역시 메모리에 해당된다. 

## **2) 메모리 계층 구조**

프로그램이 실행되는 동안 메모리는 데이터의 입출력 장소가 되며, 이러한 기본 역할은 모든 메모리가 동일하다. 하지만 CPU를 기준으로 얼마나 거리가 먼지에 따라 사용되는 방식이 조금씩 다르다. CPU와 가까울수록 빠르고 멀수록 느리다. 동시에 CPU와 가까울수록 용량이 작고 멀수록 용량이 크다. 결론적으로 메모리는 다음과 같은 계층구조를 지니게 된다. 

![image](https://user-images.githubusercontent.com/96677719/212539582-4cbb4f18-4e56-4e7f-a3a3-7db1d3905897.png)

위처럼, CPU에서 가까운 순서대로 접근한 뒤, 원하는 데이터가 없으면 더 멀리 있는 곳까지 접근하는 방식으로 데이터를 구한다. 이렇게 여러번 방문하는 것이 더 비효율적으로 보일지 몰라도 실제로 우리가 사용하는 프로그램 실행 과정을 살펴보면 메인 메모리를 제외한 L1, L2 캐쉬에 연산에 필요한 데이터가 존재할 확률이 90% 이상이나 된다. 이런 이유로 캐쉬와 메모리 계층 구조는 속도를 향상시키는데에 분명하게 도움이 된다고 볼 수 있다. 

<br/>

# **2. 캐쉬와 캐쉬 알고리즘**

## **1) 컴퓨터 프로그램의 일반적 특성**

컴퓨터 프로그램은 일반적으로 템퍼럴 로컬리티와 스페이셜 로컬리티라는 특성을 갖는다. 템퍼럴 로컬리티는 한번 접근이 이루어진 주소의 메모리 영역은 자주 접근하게 될 확률이 높다는 특성이며, 스페이셜 로컬리티는 한번 접근한 영역 인근 영역에는 접근하게 될 확률이 높다는 특성이다. 이러한 특성 덕분에 캐쉬는 성능 향상에 도움이 된다. 캐쉬 알고리즘은 기본적으로 이러한 특성을 바탕으로 구현된다. 또, 프로그래머 역시 이러한 특성을 살려서 캐쉬의 도움을 많이 받을 수 있도록 프로그램을 설계할 수 있는데, 이를 두고 캐쉬 프렌들리 코드라고 한다. 

## **2) 캐쉬 알고리즘**

![image](https://user-images.githubusercontent.com/96677719/214404586-7ec1f5ed-f559-44d4-a0f9-a9c98c5b953c.png)

ALU 연산 과정 중 필요한 데이터가 있다면 이를 레지스터로 이동시켜야 한다. 해당 데이터가 레지스터에 없다면 가장 먼저 L1 캐쉬를 살펴보게된다. 이떄 L1 캐쉬에 해당 데이터가 존재한다면 이를 가리켜 Cache Hit이 발생했다고 하며, 존재하지 않는다면 Cache Miss가 발생했다고 한다. 이때 데이터의 이동은 블록 단위로 진행이 된다. 예를 들어 L1 캐쉬에서 캐쉬 미스가 났다면 L2 캐쉬로 이동하는 데이터의 단위는 기존에 찾던 주소를 포함하는 하나의 블록이 된다. 필요로 하는 데이터만 보내는 것이 아니라, 블록 단위로 전송을 해서 스페이셜 로컬리티의 특성을 성능 향상에 활용하는 것이다. 그림 상에서도 볼 수 있듯이, 메모리 계층 구조의 하단으로 내려갈 수록 블록의 크기가 커진다. 이는 아래에 존재하는 메모리일수록 접근 횟수를 줄이는 효과를 가져다준다. 

만약 L1 캐쉬에서 캐쉬 미스가 나서, L2 캐쉬에서 해당 데이터 블록을 읽어온다면 이를 어디에 저장할지 역시 하나의 논의거리가 된다. 이에 대한 알고리즘을 두고 블록 교체 알고리즘이라 하는데, 일반적으로 블록 교체 알고리즘은 캐쉬 교체 정책에 따라 달라진다. 가장 보편적으로 거론되는 것은 LRU(Least - Recently - Used) 알고리즘으로, 단어 그대로 가장 오래 전에 참조된 블록을 밀어내는 알고리즘이다. 

<br/>

# **3. 가상 메모리**

## **1) 페이징 기법**

32bit 시스템에서 프로세스를 생성하면 4GB의 메모리를 할당받을 수 있다. 그러나 메인 메모리의 크기는 여기에 턱없이 부족하다. 따라서 4GB는 물리적으로는 존재하지 않는 가상의 주소임을 알 수 있다. 이렇게 가상 주소 지정을 통해 할당받는 4GB를 가리켜 가상 메모리 공간이라고 한다. 가상 메모리 시스템 구현 방법은 표준으로 정해져 있지 않지만, 대부분의 시스템에서 일반적으로 페이징 기법을 많이 사용한다. 

## **2) 하드디스크의 사용**

<br/>

# **출처**

뇌를 자극하는 윈도우즈 시스템 프로그래밍, 윤성우, 한빛미디어
