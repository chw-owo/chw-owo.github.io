---
title: 메모리 관리와 IO 1) 컴퓨터 구조 (4)
categories: WindowsSystem
tags: 
toc: true
toc_sticky: true
---

이 포스트는 윤성우님의 <뇌를 자극하는 윈도우즈 시스템 프로그래밍 (한빛미디어)> 내용을 바탕으로 공부한 내용을 정리한 것입니다. 

# **1. 메모리**

## **1) 메모리의 종류**

**메인 메모리**

메인 메모리가 반드시 램이어야 할 이유는 없으나 대부분의 컴퓨터에서 메인 메모리로 램, 정확히는 D-RAM 계열의 메모리를 사용하기 때문에 이 두 용어를 같이 사용하는 경우가 많다. 

**레지스터**

CPU에 내장되어 연산을 위한 저장소를 제공한다. 저장소라는 의미에서 이 역시 메모리의 일부이다. 

**캐쉬**

일반적으로 D-RAM 보다 빠른 S-RAM으로 구성되는데, 이는 CPU와 램 사이에서 중간 저장소 역할을 하는 메모리이다. CPU에 근접한 메모리이지 CPU의 일부로 존재하는 메모리는 아니다. 

**하드디스크 및 그 외 저장 장치**

하드디스크 역시 크고 작은 파일들을 저장하기 위한 용도로 사용되며, 프로그램 실행에서도 중요한 의미를 지닌다. 그 외에 SD 카드, CD ROM 같은 IO 장치 역시 메모리에 해당된다. 

## **2) 메모리 계층 구조**

프로그램이 실행되는 동안 메모리는 데이터의 입출력 장소가 되며, 이러한 기본 역할은 모든 메모리가 동일하다. 하지만 CPU를 기준으로 얼마나 거리가 먼지에 따라 사용되는 방식이 조금씩 다르다. CPU와 가까울수록 빠르고 멀수록 느리다. 동시에 CPU와 가까울수록 용량이 작고 멀수록 용량이 크다. 결론적으로 메모리는 다음과 같은 계층구조를 지니게 된다. 

![image](https://user-images.githubusercontent.com/96677719/212539582-4cbb4f18-4e56-4e7f-a3a3-7db1d3905897.png)

위처럼, CPU에서 가까운 순서대로 접근한 뒤, 원하는 데이터가 없으면 더 멀리 있는 곳까지 접근하는 방식으로 데이터를 구한다. 이렇게 여러번 방문하는 것이 더 비효율적으로 보일지 몰라도 실제로 우리가 사용하는 프로그램 실행 과정을 살펴보면 메인 메모리를 제외한 L1, L2 캐쉬에 연산에 필요한 데이터가 존재할 확률이 90% 이상이나 된다. 이런 이유로 캐쉬와 메모리 계층 구조는 속도를 향상시키는데에 분명하게 도움이 된다고 볼 수 있다. 

<br/>

# **2. 캐쉬와 캐쉬 알고리즘**

## **1) 컴퓨터 프로그램의 일반적 특성**

컴퓨터 프로그램은 일반적으로 템퍼럴 로컬리티와 스페이셜 로컬리티라는 특성을 갖는다. 템퍼럴 로컬리티는 한번 접근이 이루어진 주소의 메모리 영역은 자주 접근하게 될 확률이 높다는 특성이며, 스페이셜 로컬리티는 한번 접근한 영역 인근 영역에는 접근하게 될 확률이 높다는 특성이다. 이러한 특성 덕분에 캐쉬는 성능 향상에 도움이 된다. 캐쉬 알고리즘은 기본적으로 이러한 특성을 바탕으로 구현된다. 또, 프로그래머 역시 이러한 특성을 살려서 캐쉬의 도움을 많이 받을 수 있도록 프로그램을 설계할 수 있는데, 이를 두고 캐쉬 프렌들리 코드라고 한다. 

## **2) 캐쉬 알고리즘**

![image](https://user-images.githubusercontent.com/96677719/214404586-7ec1f5ed-f559-44d4-a0f9-a9c98c5b953c.png)

ALU 연산 과정 중 필요한 데이터가 있다면 이를 레지스터로 이동시켜야 한다. 해당 데이터가 레지스터에 없다면 가장 먼저 L1 캐쉬를 살펴보게된다. 이떄 L1 캐쉬에 해당 데이터가 존재한다면 이를 가리켜 Cache Hit이 발생했다고 하며, 존재하지 않는다면 Cache Miss가 발생했다고 한다. 이때 데이터의 이동은 블록 단위로 진행이 된다. 예를 들어 L1 캐쉬에서 캐쉬 미스가 났다면 L2 캐쉬로 이동하는 데이터의 단위는 기존에 찾던 주소를 포함하는 하나의 블록이 된다. 필요로 하는 데이터만 보내는 것이 아니라, 블록 단위로 전송을 해서 스페이셜 로컬리티의 특성을 성능 향상에 활용하는 것이다. 그림 상에서도 볼 수 있듯이, 메모리 계층 구조의 하단으로 내려갈 수록 블록의 크기가 커진다. 이는 아래에 존재하는 메모리일수록 접근 횟수를 줄이는 효과를 가져다준다. 

만약 L1 캐쉬에서 캐쉬 미스가 나서, L2 캐쉬에서 해당 데이터 블록을 읽어온다면 이를 어디에 저장할지 역시 하나의 논의거리가 된다. 이에 대한 알고리즘을 두고 블록 교체 알고리즘이라 하는데, 일반적으로 블록 교체 알고리즘은 캐쉬 교체 정책에 따라 달라진다. 가장 보편적으로 거론되는 것은 LRU(Least - Recently - Used) 알고리즘으로, 단어 그대로 가장 오래 전에 참조된 블록을 밀어내는 알고리즘이다. 

<br/>

# **3. 가상 메모리**

## **1) 페이징 기법**

32bit 시스템에서 프로세스를 생성하면 4GB의 메모리를 할당받을 수 있다. 그러나 메인 메모리의 크기는 여기에 비해 턱없이 부족하다. 따라서 4GB는 물리적으로는 존재하지 않는 가상의 주소임을 알 수 있다. 이렇게 가상 주소 지정을 통해 할당받는 4GB를 가리켜 가상 메모리 공간이라고 한다. 가상 메모리 시스템 구현 방법은 표준으로 정해져 있지 않지만, 대부분의 시스템에서 일반적으로 페이징 기법을 많이 사용한다. 

만약 16KB의 메인메모리에 프로세스별로 64KB 가상 메모리를 할당해야 한다고 가정해보자. 이때 최대 할당 가능한 실제 메모리 번지는 16KB -1 번지이다. 그러나 실제로는 프로그램이 64KB를 전부 사용하지 않을 확률이 더 높을 것이다. MMU (Memory Management Unit)은 16KB의 메모리를 CPU가 64KB 로 느끼도록 컨트롤 하는 역할을 한다. 최근에는 실제로 MMU가 CPU와 함게 하나로 패키징 되어있는 경우가 많다. CPU는 메모리로 직접 접근을 하지 않고 MMU를 통해 메모리 할당 요청을 한다. 만약 CPU가 1K 번지를 시작으로 20바이트를 할당하라고 한다면 MMU는 메인메모리에서 아직 사용되지 않은 메모리 블록 하나를 골라서 할당한다. 이를 그림으로 표현하면 아래와 같다.  

![image](https://user-images.githubusercontent.com/96677719/214494805-01d3449c-db22-4bd3-b8fb-207973435d60.png)

위 그림을 보면 4KB로 메인 메모리를 나눈 것, 그리고 1K번지부터 20바이트만 요청했으나 실제로는 $KB 블록을 모두 지정해주는 것을 확인할 수 있다. 위 그림에서는 메모리 할당의 단위가 4KB인 셈이다. 때문에 메모리 할당의 범위는 0-4K, 4-8K, 8-12K... 와 같은 방식으로 증가한다. 블록의 단위를 없애버리고 필요한 만큼만 할당할 경우 메모리 사용의 효율성은 증가하지만 MMU가 해야할 연산이 늘어나면서 속도의 감소로 이어진다. 이때 위 예시에서 임의로 정한 4KB의 블록을 하드웨어 입장에서 페이지 프레임, 소프트웨어 입장에서 페이지라고 부른다. 즉, 페이지 프레임은 실제 메인 메모리 블록을 의미하고 페이지는 가상 메모리 블록을 의미한다. 물론 페이지 프레임과 페이지의 크기는 일치한다. 


![image](https://user-images.githubusercontent.com/96677719/214495968-9a31365c-8a51-435d-bcdc-037478edd567.png)

위 그림은 가상 메모리와 실제 물리 메모리가 어떻게 매핑 되는지를 보여준다. 0-4KB의 블록은 물리메모리 가장 위쪽에 매핑되어, CPU가 이 사이에 있는 데이터를 요구할 경우 MMU는 매핑된 물리 매모레를 참조하여 데이터를 전송해준다. 이때 페이지 테이블은 내부적으로 아래와 같이 구성된다. 

![image](https://user-images.githubusercontent.com/96677719/214496532-5cbfe3be-7386-4223-a282-dc354e7ed82e.png)

(사진 출처: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sqlmvp&logNo=140191559473)

위처럼 페이지 프레임을 결정하는 비트와 페이지 프레임 내의 위치를 결정하는 비트로 구성된다. 페이지 테이블의 Key는 페이지 숫자, Value는 해당 페이지가 존재하는 페이지 프레임의 시작 번지이다. 이러한 테이블 구성을 파탕으로 페이지 테이블을 참조하여 가상 주소를 실제 할당되어 있는 물리 주소로 변환할 수 있다. 

## **2) 하드디스크의 사용**

램의 메모리가 부족할 때, 스왑 파일 개념을 도입하여 RAM에 해당하는 메인 메모리의 기능을 하드디스크로 확장할 수 있다. 하드디스크는 RAM에 비해 속도가 느리기 때문에, 스왑 파일을 통해 RAM를 보조하는 역할을 할 뿐 RAM와 동일한 역할을 하는 것은 아니다. 사용될 확률이 가장 낮은 블록을 하드 디스크에 저장하고, 만약 그 영역의 블록이 필요할 경우 다시 하드디스크에서 RAM으로 가져온다. 이때 RAM과 하드디스크 사이의 데이터 이동 기본 단위는 페이지 프레임의 크기와 동일하다. 만약 프로세스 A를 실행하던 중 이를 정지하고 프로세스 B를 실행한다고 가정해보자. RAM에 존재하는 프로세스 A 실행을 위한 데이터를 프로세스 A의 스왑파일에 저장하고, 이를 하드디스크에 저장한다. 그리고 프로세스 B의 스왑파일로부터 필요한 데이터를 가져와 RAM에 올린다. 

<br/>

# **출처**

뇌를 자극하는 윈도우즈 시스템 프로그래밍, 윤성우, 한빛미디어
