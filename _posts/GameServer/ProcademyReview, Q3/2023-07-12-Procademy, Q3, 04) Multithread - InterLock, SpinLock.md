---
title: Procademy, Q3, 04) Multithread - InterLock, SpinLock
categories: ProcademyReview
tags: 
toc: true
toc_sticky: true
---

이 포스트는 프로카데미 (게임 서버 아카데미) 수업을 바탕으로 공부한 내용을 정리한 것입니다. 

# **1. Lock**

컨테이너를 여러개의 스레드에서 사용한다면 동기화가 필요하다. 동기화가 필요한 요소는 두가지인데 하나는 자료구조 컨테이너 자체이고 또 하나는 들어있는 데이터에 대한 원자성 보장이다. 순회, 검색과 같은 읽기만 한다면 컨테이너 동기화가 필요하지 않지만 수정, 삭제, 추가와 같은 쓰기가 들어간다면 필요하다. 이때 배열의 경우 순차적으로 데이터가 들어가기에 컨테이너에 대한 동기화는 생략될 수 있다. 과거에는 쓰기가 포함되면 무조건 Lock을 걸었는데 최근에는 ReadWriteLock이라는 동기화 객체를 통해 share와 exclusive를 분류하여 동기화를 걸고 있다. 

<br/>

# **2. InteredLock**

이는 내부적으로 atomic 연산자를 사용해서 동기화를 보장하는 동기화 방법으로 동기화 객체를 쓰지 않는다. InterlockedIncrement, compare_exchange 등이 모두 이 항목에 포함된다. InterlockedIncrement는 매크로이며 실제로는 _InterlockedIncrement를 인라인 호출한다. 어셈블리를 보면 lock inc를 사용하는데, lock이 붙은 어셈블리는 atomic 하게 수행하는 명령어를 의미한다. 

여러 코어에서 동시에 lock inc를 요청해도 오염되지 않기 위해서는 동기화가 필요하다. 따라서 두개 이상의 코어에서 같은 영역을 대상으로 Interlocked 함수를 실행하면 해당 메모리가 있는 캐시 라인 전체에 Lock을 걸어버린다. 따라서 CPU 입장에서는 명령어가 한 박자 느리게 동작하며 그 명령어를 수행하기까지, 즉 캐시 라인에 Lock이 풀릴 때까지 CPU가 잠시 멈춘다. 즉 OS 관점이 아닌 CPU 관점에서의 동기화가 이루어진다. 

무관한 두 변수에 대해 Interlocked를 실행한다면 캐시 라인을 분리하는 것이 Lock으로 인한 경합을 줄일 수 있다. 그렇다고 다 분리하면 캐시가 낭비되므로 전혀 상관 없는 변수들 사이에 끼워넣는 것이 더 낫다. 보통 변수를 용도 별로 모아두는 걸 선호하는데 이 경우 성능을 위해 가독성을 버리는 게 된다. 

보통 Interlock 함수는 커널모드 전환도, 객체 생성도 없기 때문에 효율적이고 빠르다고 표현한다. 그러나 이는 순서를 보장해야 하기 때문에 비순차적 명령어 처리가 어려워진다. 따라서 이 함수를 포함해 atomic 연산이 쓰이면 분기 예측과 ordering buffer에 있던 내용을 다 버리기 때문에 성능에 영향을 준다. 물론 동기화 객체로 Lock을 거는 것보다는 가볍지만 도배해도 될 만큼 가벼운 함수는 아니다. 

4byte 변수가 2의 경계에 서있다면 atomic한 연산을 보장할 수 없다. 일반적인 사용엔 문제가 없는데 구조체를 잘못 쓰거나, pragma pack을 잘못 걸거나, 힙을 통해 임의로 할당받은 영역에 포인터 접근을 통해 임의로 데이터를 배치 했을 때 등의 상황에선 문제가 생길 수 있다. 여기에 Interlock을 거는 것 자체가 다소 이상한 예시이지만, 예를 들자면 구조체 캐스팅으로 데이터를 받아 오는 경우에 문제가 될 수 있다. 이때 차라리 예외를 내면 좋을텐데 예외도 안나고 되는 척 넘어가며 나중에 데이터 오염으로 이 상황을 알게 될 수도 있으니 유의해야 한다. 물론 일반적인 상황에서는 이럴 일이 잘 없다. 

```c++
a = 2; 
InterlockedIncrement(&a); b = a; 
```

```c++
InterlockedIncrement(&count); 
if(count == 1000);
```
Interlock은 변한 값을 return 한다. 이때 첫번째와 같은은 코드를 시도하면 a는 3을 보장할 수 있지만 다른 스레드에서 b에 접근 했을 수도 있기 때문에 b는 3이 아닐 수도 있다. 같은 이유로 두번째와 같은 같은 사용도 피해야 한다. 두 스레드가 동시에 1000을 감지하거나 어떤 스레드도 감지하지 못하고 넘어갈 수도 있다. 

InterlockedExchange는 atomic한 값 대입을 보장한다. 이때 mov는 원래 atomic 하기 때문에 단순히 대입만 하고 싶다면 굳이 쓸 필요가 없다. 이 함수는 이전 값을 반환하기 때문에 true에서 true로 바꾼 건지, false였던 걸 true로 바꾼 건지 같은 것을 atomic 하게 확인하고 싶을 때 유용하다. 

이때 Interlock이 걸리면 실질적으로 일을 하지는 않지만 해당 스레드는 Running 상태이기 때문에 CPU 사용률이 100%가 나옴. lock inc는 최소단위 오퍼레이션인데 이게 느리게 되는 상황이므로 이걸 기다리는 동안은 인터럽트 처리도 되지 않는다. 즉, Interlock으로 접근하는 스레드가 매우 많을 경우 이것이 하드웨어와의 통신에도 영향을 줄 수 있으니 주의해야 한다.  

<br/>

# **3. SpinLock**

동기화 객체를 써서 block을 걸면 해당 스레드는 CPU를 차지하지 않는다. 반면 스핀락은 스레드를 running 상태로 유지하며 성공할 때까지 재시도 하는 것이다. 동기화 객체를 쓰면 컨텍스트 스위칭으로 block이 되고, signal을 받아 디스패쳐 되어야 lock을 얻는다. 반면 스핀락은 컨텍스트 스위칭 없이 자신이 진입할 수 있을 때 바로 진입 할 수 있다. 물론 퀀텀이 떨어지면 바뀌기에 스핀락을 쓴다고 스위칭이 없는 것은 아니다. 따라서 퀀텀 내에 성공할 만큼 빠르게 lock을 획득할 수 있는 경우여야만 스핀락이 유용하다. 

while 안에서 전역 flag가 0이 되길 기다리고, 0이 되면 1로 바꾼 뒤 while을 빠져나오는 식으로 구현한다. InterlockExchange (ret이 1이면 마저 돌기) 혹은 compare_exchange를 써야 atomic 하게 처리할 수 있다. 전역 flag를 대신 동기화 걸고 싶은 변수를 인자로 받아서 변화를 감지하는 방식으로 쓸 수도 있다. 일부는 Unlock 할 때도 InterlockExchange 쓰길 권장한다. OS에 따라 비순차적 명령어에 의해 순서가 바뀌면서 다른 곳에서 flag를 0으로 바꿀 수도 있기 때문이다. x86은 제한적인 ordering을 쓰기 때문에 그냥 flag = 0을 해도 되지만, 범용적인 아키텍쳐를 고려할 경우 Interlock을 쓰는 것이 좋다. 

정말 필수적인 코드라면 제한적으로 쓸 수도 있지만 요즘은 스핀락을 만들어 쓰진 않는다. 또, 이렇게 해서 CPU를 빨리 차지한다고 해도 그게 좋은 형태라고 보장할 수 없다. block 걸리고 다른 스레드에게 양보하는 게 나을 수도 있기 때문이다. 요즘은 OS도 언어도 동기화 객체를 퀀텀이 지나기 전까지는 스핀락으로 시도해보다가 그 안에 획득이 안되면 동기화 객체로 동작하게끔 구현하고 있다. 

<br/>

# **4. pause와 spinlock 구현**

스핀락에서 최악의 상황은 현 스레드 + 스핀락으로 대기하는 스레드의 개수가 코어 개수보다 많아지는 상황이다. 그러면 스핀락 코드가 실제로 돌고 있는 스레드를 방해하면서 오히려 실행 중인 코드가 느려질 수 있다. 이 때문에 스핀락 구현에서 while 마지막에 sleep(0)을 넣어주는 예제가 많다. 이렇게 하면 전체적으로 성능이 나아지는 느낌을 받을 수도 있다. 

그러나 이렇게 할 경우 스핀락이 아니다. 스핀락은 퀀텀을 포기하지 않고 이번 퀀텀 내에 잡을 수 있다면 잡겠다는 의미인데 이는 퀀텀을 포기하는 것이기 때문이다. 따라서 스위칭은 스위칭 대로 하고 cpu는 cpu대로 먹는 비효율적 상황이 된다. 애초에 코어 개수가 부족하면 차라리 동기화를 걸고 기다리는 것이 낫다. 이때 sleep 대신 들어가야 하는 것이 yield processor이다.

사실 하이퍼 스레딩은 정말 CPU 두개인 게 아니라, 두 스레드의 명령어를 쌓아 놓고 서로 연관이 없다면 다 처리해버리는 구조이다. 그래서 실제로는 명령어들이 뒤섞여있으며, 속도가 2배가 아닌 1.n배 정도만 향상 된다. 현 아키텍쳐에서는 하이퍼 스레딩의 경우 L1 Cache를 공유, 즉 절반만 사용 하기 때문에 이로 인해 Cache miss가 늘어나기도 한다. 이 때문에 이 기능을 끄는 경우도 많다. 

이때 yield processor를 쓰면 퀀텀은 포기하지 않되, 즉 컨텍스트 스위칭은 하지 않되 일부러 빈 명령어를 넣어서 다른 쪽 스레드 명령어를 먼저 수행하도록 양보한다. 이런 이유로 yield processer는 하이퍼 스레드에서만 의미가 있다. MS도 스핀락 코드에 다 이걸 넣고 있다. 어셈블리어에서는 pause가 동일한 명령어를 의미한다. 